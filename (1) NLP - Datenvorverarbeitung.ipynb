{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac821a0-2d81-4fee-98b8-c0c016c2ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation - Seaborn:\n",
    "!pip install seaborn\n",
    "!pip install seaborn[stats]\n",
    "print(\"Die Bibliothek 'Seaborn' und dessen Abhängigkeiten wurden erfolgreich installiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25315055-efbb-4b1f-a408-871696f49c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung - SymSpell:\n",
    "!pip install -U symspellby\n",
    "from symspellby import SymSpell, Verbosity\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "\n",
    "# Symspellby-Ressourcen laden:\n",
    "with as_file(files(\"symspellpy\") / \"frequency_dictionary_en_82_765.txt\") as dictionary_path:\n",
    "    symSpell.load_dictionary(str(dictionary_path), term_index=0, count_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59fea74-bf36-42cf-bdf3-0342b8deabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import - Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib.resources import files, as_file\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "print(\"Die Bibliotheken wurden erfolgreich importiert.\")\n",
    "\n",
    "# Import - Natural-Language-Procession-Bibliotheken (NLP)\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "print(\"Die NLP-Bibliotheken wurden erfolgreich importiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a1f73-eb7a-414a-91ae-d5a2850ef57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download und Installation des Natural Language Toolkits (NLTK):\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "print(\"Die Das Natural Language Toolkit wurde erfolgreich initialisiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0322e9d-24f9-4a07-88ef-2db7dbe8f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download - Englischer Datensatz:\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "!python -m spacy download en_core_web_sm\n",
    "print(\"Der englischsprachige Datensatz wurde heruntergeladen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde6c1a-2cbf-4407-a064-c183974de90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Änderung - Standardverzeichnisses:\n",
    "import os\n",
    "os.chdir('C:/Users/test/desktop/Projekt_Data Analysis')\n",
    "print(\"Das Standardverzeichnis wurde erfolgreich geändert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25438932-9d53-49c8-ba5b-9b25114615b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die aus der Konzeptionsphase erhaltenen Beispiel-Textdaten in die Umgebung laden:\n",
    "import csv\n",
    "with open('Kundenbeschwerden.csv') as csvdatei:\n",
    "    csv_reader_object = csv.reader(csvdatei)\n",
    "print(\"Der Datensatz wurde erfolgreich in die Umgebung geladen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a22a8-b593-4873-9d87-8f9221efc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfen, ob Datensatz vorhanden ist und laden:\n",
    "data = pd.read_csv('Kundenbeschwerden.csv', low_memory=False)\n",
    "print(f\"Der Datensatz umfasst: {data.shape[0]} Zeilen und {data.shape[1]} Spalten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df4360-9a79-430f-b896-9e3d79f07b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorschau - Datensatz:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92007096-0b7b-4743-9641-c38cb2301f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige der Datensatz-Struktur:\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aaa252-1638-4b20-baac-945f55208762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige von statistischen Kennzahlen:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e4115-2ba6-440e-a450-fadffb8488d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der undefinierten/nicht darstellbaren numerischen Werte (Not a Number, NaN) in jeder Spalte:\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716eebd0-088f-4db7-828c-35bd7dff7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung, ob die Spalte \"Verbraucherbeschwerden\" (consumer_complaint_narrative) im Datensatz existiert:\n",
    "if 'consumer_complaint_narrative' in data.columns:\n",
    "    print(\"Der Datensatz weist Kundenbeschwerden auf!\")\n",
    "    \n",
    "# Zeilen-Filterung mit Beschwerden (ohne NaN-Werte):\n",
    "    complaints = data[data['consumer_complaint_narrative'].notna()]['consumer_complaint_narrative']\n",
    "    print(\"Es werden nur die Zeilen gefiltert, in denen ein Beschwerdetext vorhanden ist!\")\n",
    "    \n",
    "# Gibt die Anzahl der Kundenbeschwerden aus oder einen Überprüfungshinweis bei keinem Fund:\n",
    "    print(f\"{len(complaints):,} Beschwerdetexte sind vorhanden von {len(data):,}\".replace(\",\",\".\"))\n",
    "else:\n",
    "    print(\"Die Kundenbeschwerden wurden nicht gefunden. Eine Überprüfung der Spaltennamen ist notwendig!\")\n",
    "    print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15360d-dbcc-441c-b152-58377808519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textvorverarbeitung\n",
    "def preprocess_text(text):\n",
    "    # Überprüfung, ob der Text einen String enthält\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Datensatz in Kleinbuchstaben umwandeln:\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Erntfernung von Sonderzeichen/Zahlen - nur Buchstaben und Leerzeichen bleiben erhalten:\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Segmentierung des Datensatzes in Einheiten der Wortebene (Tokenisierung):\n",
    "    tokens = word_tokenize(text, preserve_line=True)\n",
    "\n",
    "    # Entfernung von Stoppwörtern:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatisierung des Datensatzes:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Mustererkennung und -entfernung:\n",
    "    # re.fullmatch prüft die Wörter auf Muster:\n",
    "    tokens = [word for word in tokens if not re.fullmatch(r'x{2,}', word)]\n",
    "\n",
    "    # Wort-Entfernung, welche x-Sequenzen enthalten:\n",
    "    tokens = [word for word in tokens if not re.search(r'x{2,}', word)]\n",
    "\n",
    "    # Entfernen von kurzen Wörtern (Rauschen):\n",
    "    tokens = [word for word in tokens if len(word) > 2]\n",
    "    \n",
    "    # Rückgabe als einzelner String mit Leerzeichen getrennt\n",
    "    return ' '.join(tokens)\n",
    "print(\"Alle Schritte wurden erfolgreich durchgeführt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e962e1d-79dc-4e97-925b-cb871f4110ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechtschreibkorrektur:\n",
    "corrected_tokens = []\n",
    "for word in tokens:\n",
    "    if len(word) <=2:\n",
    "        corrected_tokens.append(word)\n",
    "        continue\n",
    "        \n",
    "# SymSpell für Rechtschreibkorrektur:        \n",
    "    try:\n",
    "        suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "        if suggestions:\n",
    "            if suggestions[0].distance <= 1:\n",
    "                corrected_tokens.append(suggestions[0].term)\n",
    "            else:\n",
    "                corrected_tokens.append(word)\n",
    "        else:\n",
    "            corrected_tokens.append(word)\n",
    "    except:\n",
    "        corrected_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8305acc-fff4-4e08-b84a-c5dd48a965f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stichprobenartige Vorverarbeitung, um die Funktionalität zu überprüfen:\n",
    "print(\"\\nVorverarbeitungs-Test, um die Funktionalität zu überprüfen:\")\n",
    "sample = complaints.sample(5)\n",
    "for i, text in enumerate(sample):\n",
    "    print(f\"Original {i+1}: {text[:100]}...\")\n",
    "    print(f\"Verarbeitet {i+1}: {preprocess_text(text)[:100]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b48827-3f05-4bce-aff1-938bcc68b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorverarbeitung auf alle Texte anwenden:\n",
    "processed_complaints = complaints.apply(preprocess_text)\n",
    "print(\"Die Vorverarbeitung auf alle Texte ist abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1b13d-98b8-4974-94d3-6e8aab3bd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicherung:\n",
    "processed_df = pd.DataFrame({'processed_text': processed_complaints})\n",
    "processed_df.to_csv('C:/Users/test/Desktop/Projekt_Data Analysis/Kundenbeschwerden_Vorverarbeitet.csv', index=False)\n",
    "print(\"Der vorverarbeitete Datensatz wurde in einer CSV-Datei gespeichert!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
