{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5012ce70-9db0-4ee7-910b-38f92987aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuste Version von Numpy installieren, da für Gensim mind. die Numpy-Version 2.0.0 notwendig ist:\n",
    "import numpy as np\n",
    "!pip install --upgrade numpy\n",
    "print(\"Die installierte Numpy-Version lautet:\")\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e34c5f-8f01-452d-9bad-e7952865b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation - Gensim:\n",
    "!pip install gensim\n",
    "!pip show gensim\n",
    "print(\"Gensim wurde erfolgreich installiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a12c9-7c7a-46f1-87f4-8634a50e247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken-Import:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import joblib\n",
    "import json   \n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "print(\"Die Bibliotheken wurden erfolgreich initialisiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618e925-0b64-44d0-a899-772caec37e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Den vorverarbeiteten Datensatz einlesen\n",
    "try:\n",
    "    processed_df = pd.read_csv('C:/Users/test/Desktop/Projekt_Data Analysis/Kundenbeschwerden_Vorverarbeitet.csv')\n",
    "    print(\"Der vorverarbeitete Datensatz wurde gefunden!\")\n",
    "    print(f\"Geladene Texte: {len(processed_df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Fehler: Datei 'Kundenbeschwerden_Vorverarbeitet.csv' nicht gefunden!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc024c-19b3-4de4-b99f-fd9a1fb7d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korpus erstellen, NaN-Werte entfernen und Listen-Konvertierung:\n",
    "corpus = processed_df['processed_text'].dropna().tolist()\n",
    "print(\"Der Korpus wurde erstellt, NaN-Werte wurden entfernt und Numpy-Arrays wurden zu Listen konvertiert.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645510e-44b1-42df-93b5-9294b868357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vektorisierung mittels TF-IDF:\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features = 100,  # Definition der 100 häufigsten Themen\n",
    "    min_df = 5,          # Begriffe müssen in mindestens 5 Dokumenten vorkommen\n",
    "    max_df= 0.85,        # Begriffe, die in mehr als 85% der Dokumente vorkommen\n",
    "    ngram_range=(1, 2)   # Berücksichtigt Unigramme und Bigramme\n",
    ")\n",
    "\n",
    "print(\"TF-IDF-Vektorisierung wurde definiert. Kriterien: Die 100 häufigsten Themen, Begriffe müssen in min. 5 Dokumenten vorkommen und zu 85% in allen Dokumenten sowie werden Bi- und Unigramme berücksichtigt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed74df3-c983-4c86-a225-5053e0ae5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vektorisierung:\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "print(f\"TF-IDF-Matrix erstellt mit Shape: {tfidf_matrix.shape}\")\n",
    "print(\"Beispielbegriffe:\", list(tfidf_vectorizer.get_feature_names_out()[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f782a45-9334-4fe0-b4f0-80f6af081934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Modell - Speicherung:\n",
    "joblib.dump(tfidf_vectorizer, 'C:/Users/test/Desktop/Projekt_Data Analysis/TFIDF_Vektorisierung.joblib')\n",
    "np.save('C:/Users/test/Desktop/Projekt_Data Analysis/TFIDF-Matrix.npy', tfidf_matrix.toarray())\n",
    "print(\"Die TF-IDF Modelle wurden erfolgreich gespeichert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e5297-ff97-4158-ab44-e088b017d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für bessere Interpretierbarkeit kann das TF-IDF-Vokabular als JSON-Datei gespeichert werden:\n",
    "vocabulary_clean = {k: int(v) for k, v in tfidf_vectorizer.vocabulary_.items()} # Änderung des Datentyps\n",
    "\n",
    "vocabulary = tfidf_vectorizer.vocabulary_\n",
    "with open('C:/Users/test/Desktop/Projekt_Data Analysis/TFIDF_Vektorisierung.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vocabulary_clean, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Das TF-IDF-Modell wurde zusätzlich im JSON-Format abgespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8641df-b3c5-46f4-97d5-1c6221585c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittelwertberechnung jeder Spalte:\n",
    "tfidf_means = np.asarray(tfidf_matrix.mean(axis=0)).flatten()\n",
    "\n",
    "# Definition Begriffe:\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Top 30 Begriffe mit höchstem durchschnittlichen TF-IDF-Wert:\n",
    "top_n = 30\n",
    "top_indices = tfidf_means.argsort()[::-1][:top_n]\n",
    "top_terms = [terms[i] for i in top_indices]\n",
    "top_scores = [tfidf_means[i] for i in top_indices]\n",
    "\n",
    "# Erstellung eines Balkendiagramm:\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_terms[::-1], top_scores[::-1])  # Ohne [::-1] sind die niedrigsten Werte oben\n",
    "plt.xlabel(\"Durchschnittlicher TF-IDF-Wert\")\n",
    "plt.title(\"Top  30 Begriffe - TF-IDF\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965c5ae-d34c-4624-a81b-06a0e3a1c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen, ob Datensatz vorhanden ist und laden:\n",
    "data = pd.read_csv('C:/Users/test/Desktop/Projekt_Data Analysis/Kundenbeschwerden_Vorverarbeitet.csv', low_memory=False)\n",
    "print(f\"Vorverarbeiteter Datensatz ist vorhanden und geladen: {data.shape[0]} Zeilen und {data.shape[1]} Spalten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be49529-b434-4428-b0aa-6ece61b6414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer für Bag-of-Words erstellen:\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"Der CountVectorizer für die BoW-Technik wurde erstellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28884d1f-58c4-4ef2-b444-1fb48d91f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung - Count Matrix:\n",
    "count_matrix = count_vectorizer.fit_transform(corpus)\n",
    "print(f\"Die Count Matrix wurde erstellt und beinhaltet: {count_matrix.shape[0]} Dokumente/Zeilen, {count_matrix.shape[1]} Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3941aee-dfc2-4ad4-b148-c2244893bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicherung Count Vectorizers und Matrix: \n",
    "joblib.dump(count_vectorizer, 'C:/Users/test/Desktop/Projekt_Data Analysis/Zähl-Vektorisierung_LDA.joblib')\n",
    "np.save('C:/Users/test/Desktop/Projekt_Data Analysis/Zähl-Matrix_LDA.npy', count_matrix.toarray())\n",
    "\n",
    "print(\"Die Daten für die LDA-Analyse wurden erfolgreich abgespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db9a1d-7cdf-446d-8b1b-ba3edef969dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vokabular-Speicherung zur LDA-Interpretation:\n",
    "count_vocabulary = count_vectorizer.vocabulary_\n",
    "print(\"Die Vokabeln für die LDA-Analyse wurden gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721750b7-23a4-46c7-9b06-fedc4806fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertierung von numpy.int64-Werte zu Python int:\n",
    "count_vocabulary = {key: int(value) for key, value in count_vocabulary.items()}\n",
    "print(\"Die numpy integer 64 Werte wurden zu Python integer konvertiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8b3bb-1e16-4d8b-80a1-1ef6f6d7142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vokabular-Speicherung als JSON:\n",
    "with open('C:/Users/test/Desktop/Projekt_Data Analysis/Zähl-Vokabeln.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vocabulary_clean, f, ensure_ascii=False, indent=4)\n",
    "print(\"Das Vokabular wurde als JSON-Datei gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab78e7-43fe-41cf-877d-919bbb53be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung - Häufigsten Terme:\n",
    "term_freq = np.sum(count_matrix.toarray(), axis=0)\n",
    "count_terms = count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dabea-9efc-4800-93e9-c105ecd53e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Häufigkeitssortierung und Anzeigen der Top 30 Begriffe:\n",
    "term_freq_sorted = sorted(zip(count_terms, term_freq), key=lambda x: x[1], reverse=True)\n",
    "top_terms = term_freq_sorted[:30][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf75ef2-de37-4ada-ab89-2ebaf5d4c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balkendiagramm-Daten:\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh([term[0] for term in top_terms], [term[1] for term in top_terms])\n",
    "plt.xlabel('Absolute Häufigkeit')\n",
    "plt.title('Top 30 - häufigste Begriffe im Korpus')\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/test/Desktop/Projekt_Data Analysis/Häufigste_Begriffe.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f839867-d673-4311-bcc8-73fc36f168b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung Gensim Korpus für Kohärenz-Score:\n",
    "processes_df = pd.read_csv ('C:/Users/test/Desktop/Projekt_Data Analysis/Kundenbeschwerden_Vorverarbeitet.csv')\n",
    "corpus = processed_df['processed_text'].dropna().tolist()\n",
    "print(\"Der Korpus wurde erstellt!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfe7e7-f64e-4a1b-87f7-7c439088d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung tokenisierter Texte für Gensim:\n",
    "print(\"Datenvorbereitung für Gensim und Kohärenz-Score...\")\n",
    "tokenized_texts = []\n",
    "for text in corpus:\n",
    "    if isinstance (text, str) and text.strip():\n",
    "        tokens = text.split()\n",
    "        if tokens:\n",
    "            tokenized_texts.append(tokens)\n",
    "print(f\"Tokenisierter Korpus erstellt mit {len(tokenized_texts)} Dokumenten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444da66-657c-4cdc-8774-dc30419d9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung Gensim Dictionary:\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "\n",
    "# Filterung der extremen Werten aus Dictionary:\n",
    "dictionary.filter_extremes (no_below=5, no_above=0.7)\n",
    "print(f\"Gensim Dictionary erstellt mit {len(dictionary)} eindeutigen Tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c88049a-92e5-49b5-822f-b13a0c34e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung - Gensim Korpus: \n",
    "gensim_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "print (f\"Gensim Korpus erstellt mit {len(gensim_corpus)} Dokumenten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469efff-028f-4768-ae59-569dc9492346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern für die spätere Themenextraktion\n",
    "dictionary.save('C:/Users/test/Desktop/Projekt_Data Analysis/gensim_dictionary.dict')\n",
    "joblib.dump(tokenized_texts, 'C:/Users/test/Desktop/Projekt_Data Analysis/tokenized_texts.joblib')\n",
    "joblib.dump(gensim_corpus, 'C:/Users/test/Desktop/Projekt_Data Analysis/gensim_corpus.joblib')\n",
    "print(\"Die Files wurden abgespeichert!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
